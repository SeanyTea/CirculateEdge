{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/roboflow-ai/yolov5-custom-training-tutorial/blob/main/yolov5-custom-training.ipynb","timestamp":1670431921597}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yNveqeA1KXGy"},"source":["# Step 1: Install Requirements"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kTvDNSILZoN9","outputId":"17aceffe-66a8-407d-b1b9-495bb3c4a02e","executionInfo":{"status":"ok","timestamp":1670431987130,"user_tz":300,"elapsed":31454,"user":{"displayName":"Sean Thammakhoune","userId":"11730667877753326319"}}},"source":["#clone YOLOv5 and \n","!git clone https://github.com/ultralytics/yolov5  # clone repo\n","%cd yolov5\n","%pip install -qr requirements.txt # install dependencies\n","%pip install -q roboflow\n","\n","import torch\n","import os\n","from IPython.display import Image, clear_output  # to display images\n","\n","print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 14378, done.\u001b[K\n","remote: Counting objects: 100% (7/7), done.\u001b[K\n","remote: Compressing objects: 100% (6/6), done.\u001b[K\n","remote: Total 14378 (delta 1), reused 4 (delta 0), pack-reused 14371\u001b[K\n","Receiving objects: 100% (14378/14378), 13.60 MiB | 15.93 MiB/s, done.\n","Resolving deltas: 100% (9902/9902), done.\n","/content/yolov5\n","\u001b[K     |████████████████████████████████| 182 kB 29.7 MB/s \n","\u001b[K     |████████████████████████████████| 62 kB 212 kB/s \n","\u001b[K     |████████████████████████████████| 1.6 MB 23.5 MB/s \n","\u001b[K     |████████████████████████████████| 42 kB 769 kB/s \n","\u001b[K     |████████████████████████████████| 178 kB 50.0 MB/s \n","\u001b[K     |████████████████████████████████| 138 kB 73.1 MB/s \n","\u001b[K     |████████████████████████████████| 67 kB 6.0 MB/s \n","\u001b[K     |████████████████████████████████| 54 kB 3.2 MB/s \n","\u001b[K     |████████████████████████████████| 145 kB 71.8 MB/s \n","\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n","\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Setup complete. Using torch 1.12.1+cu113 (Tesla T4)\n"]}]},{"cell_type":"markdown","metadata":{"id":"zP6USLgz2f0r"},"source":["# Step 2: Download Our Dataset\n","\n","We create the dataset in Roboflow, exported in the YOLOv5 format.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R2wGvjd4Z_92","outputId":"090f61fa-234d-4a7e-f69d-736d6eaba01f","executionInfo":{"status":"ok","timestamp":1670432057870,"user_tz":300,"elapsed":11883,"user":{"displayName":"Sean Thammakhoune","userId":"11730667877753326319"}}},"source":["!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"C07MwEl74KJlbJ4mfSjr\")\n","project = rf.workspace(\"sean-thammakhoune-cqknw\").project(\"urbancoworks_office\")\n","dataset = project.version(1).download(\"yolov5\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: roboflow in /usr/local/lib/python3.8/dist-packages (0.2.21)\n","Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.4.7)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.21.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.4.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.15.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from roboflow) (3.2.2)\n","Requirement already satisfied: urllib3==1.26.6 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.26.6)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (7.1.2)\n","Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.10.1)\n","Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.10)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.28.1)\n","Requirement already satisfied: opencv-python-headless>=4.5.1.48 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.6.0.66)\n","Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.10.0)\n","Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.0.0)\n","Requirement already satisfied: glob2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.7)\n","Requirement already satisfied: certifi==2021.5.30 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2021.5.30)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.21.6)\n","Requirement already satisfied: wget in /usr/local/lib/python3.8/dist-packages (from roboflow) (3.2)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (6.0)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.64.1)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->roboflow) (2.1.1)\n","loading Roboflow workspace...\n","loading Roboflow project...\n","Downloading Dataset Version Zip in OSS3-1 to yolov5pytorch: 100% [5201606 / 5201606] bytes\n"]},{"output_type":"stream","name":"stderr","text":["Extracting Dataset Version Zip to OSS3-1 in yolov5pytorch:: 100%|██████████| 1791/1791 [00:00<00:00, 3362.57it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"2jjT5uIHo6l5"},"source":["# set up environment\n","os.environ[\"DATASET_DIRECTORY\"] = \"/content/datasets\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X7yAi9hd-T4B"},"source":["# Step 3: Train Our Custom YOLOv5 model\n","\n","Here, we are able to pass a number of arguments:\n","- **img:** define input image size --img 416\n","- **batch:** determine batch size --batch 16\n","- **epochs:** define the number of training epochs --epochs 30\n","- **data:** define the data --data file_location/data.yaml\n","- **weights:** specify a path to weights to start transfer learning from --weights yolov5n.pt for nano (YOLOv5 lite)\n","- **cache:** cache images for faster training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eaFNnxLJbq4J","outputId":"f1f95b89-73da-4308-ac98-31de985c0cae","executionInfo":{"status":"ok","timestamp":1670432427565,"user_tz":300,"elapsed":300874,"user":{"displayName":"Sean Thammakhoune","userId":"11730667877753326319"}}},"source":["!python train.py --img 416 --batch 16 --epochs 2 --data OSS3-1/data.yaml --weights yolov5n.pt --cache"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5n.pt, cfg=, data=OSS3-1/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v7.0-27-g454dae1 Python-3.8.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 168MB/s]\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n.pt to yolov5n.pt...\n","100% 3.87M/3.87M [00:00<00:00, 18.0MB/s]\n","\n","Overriding model.yaml nc=80 with nc=2\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      1760  models.common.Conv                      [3, 16, 6, 2, 2]              \n","  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                \n","  2                -1  1      4800  models.common.C3                        [32, 32, 1]                   \n","  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  4                -1  2     29184  models.common.C3                        [64, 64, 2]                   \n","  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  6                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n","  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  8                -1  1    296448  models.common.C3                        [256, 256, 1]                 \n","  9                -1  1    164608  models.common.SPPF                      [256, 256, 5]                 \n"," 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 14                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n"," 18                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1     74496  models.common.C3                        [128, 128, 1, False]          \n"," 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 24      [17, 20, 23]  1      9471  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256]]\n","Model summary: 214 layers, 1766623 parameters, 1766623 gradients, 4.2 GFLOPs\n","\n","Transferred 343/349 items from yolov5n.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/OSS3-1/train/labels... 717 images, 0 backgrounds, 0 corrupt: 100% 717/717 [00:00<00:00, 1940.56it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/OSS3-1/train/images/262_png.rf.2a34f55eb7c9c899e5a0b0ec225613b1.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/OSS3-1/train/images/605_png.rf.5152549293aebdfadf39503a471111b8.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/OSS3-1/train/images/737_png.rf.b1d5b71ee53865c7f2a45a5906b9785c.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/OSS3-1/train/images/803_png.rf.91d5be373356d0d3e20cd8742c53735e.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/OSS3-1/train/labels.cache\n","\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.3GB ram): 100% 717/717 [00:00<00:00, 722.47it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/OSS3-1/valid/labels... 174 images, 0 backgrounds, 0 corrupt: 100% 174/174 [00:00<00:00, 629.81it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/yolov5/OSS3-1/valid/images/239_png.rf.11bcfaf1d4b61ed92347f93da82948c2.jpg: 2 duplicate labels removed\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/OSS3-1/valid/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 174/174 [00:00<00:00, 424.99it/s]\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.77 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to runs/train/exp/labels.jpg... \n","Image sizes 416 train, 416 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp\u001b[0m\n","Starting training for 30 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       0/29      0.74G     0.1071    0.03902    0.02524         56        416: 100% 45/45 [00:11<00:00,  4.06it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:02<00:00,  2.17it/s]\n","                   all        174        487      0.702      0.241      0.184     0.0476\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       1/29     0.862G    0.07706    0.03797   0.008094         73        416: 100% 45/45 [00:07<00:00,  5.90it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.27it/s]\n","                   all        174        487       0.24      0.779      0.293      0.115\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       2/29     0.862G    0.07097    0.03286   0.004077         67        416: 100% 45/45 [00:06<00:00,  6.56it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.51it/s]\n","                   all        174        487      0.609      0.748      0.704      0.177\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       3/29     0.862G    0.06748    0.03016   0.003645         86        416: 100% 45/45 [00:06<00:00,  6.51it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.84it/s]\n","                   all        174        487      0.887      0.922      0.964      0.383\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       4/29     0.862G    0.05735     0.0294   0.003033         60        416: 100% 45/45 [00:06<00:00,  6.47it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.60it/s]\n","                   all        174        487      0.428       0.93      0.515      0.236\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       5/29     0.862G    0.05173    0.02846   0.002442         61        416: 100% 45/45 [00:06<00:00,  6.49it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.52it/s]\n","                   all        174        487      0.801      0.911      0.927      0.419\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       6/29     0.862G    0.04575    0.02594   0.002289         51        416: 100% 45/45 [00:06<00:00,  6.55it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.79it/s]\n","                   all        174        487      0.969      0.928      0.992      0.533\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       7/29     0.862G    0.04389    0.02614   0.001991         77        416: 100% 45/45 [00:08<00:00,  5.48it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:00<00:00,  6.06it/s]\n","                   all        174        487      0.719      0.932      0.942      0.395\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       8/29     0.862G    0.04137     0.0253   0.001778         71        416: 100% 45/45 [00:06<00:00,  6.59it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.68it/s]\n","                   all        174        487      0.987      0.967       0.99      0.522\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       9/29     0.862G    0.03904     0.0254    0.00164         63        416: 100% 45/45 [00:06<00:00,  6.47it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.71it/s]\n","                   all        174        487      0.786      0.931      0.974      0.633\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      10/29     0.862G    0.03752    0.02429   0.001519         58        416: 100% 45/45 [00:06<00:00,  6.54it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:00<00:00,  6.20it/s]\n","                   all        174        487      0.987      0.988      0.989      0.528\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      11/29     0.862G    0.03602    0.02426   0.001361         49        416: 100% 45/45 [00:07<00:00,  6.38it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.89it/s]\n","                   all        174        487      0.991      0.991      0.993      0.712\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      12/29     0.862G     0.0349    0.02233   0.001241         65        416: 100% 45/45 [00:06<00:00,  6.55it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.86it/s]\n","                   all        174        487      0.995      0.995      0.995      0.644\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      13/29     0.862G    0.03247    0.02293   0.001139         74        416: 100% 45/45 [00:08<00:00,  5.49it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.72it/s]\n","                   all        174        487      0.995      0.993      0.994      0.574\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      14/29     0.862G    0.03165    0.02307   0.001085         62        416: 100% 45/45 [00:06<00:00,  6.43it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.54it/s]\n","                   all        174        487      0.997      0.997      0.995      0.734\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      15/29     0.862G    0.03126    0.02257   0.001065         68        416: 100% 45/45 [00:06<00:00,  6.46it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.80it/s]\n","                   all        174        487      0.995      0.995      0.995      0.669\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      16/29     0.862G    0.02931    0.02235  0.0009153         60        416: 100% 45/45 [00:07<00:00,  6.42it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.49it/s]\n","                   all        174        487      0.998      0.999      0.995      0.734\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      17/29     0.862G    0.02875    0.02112  0.0008402         70        416: 100% 45/45 [00:07<00:00,  6.32it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.73it/s]\n","                   all        174        487      0.995      0.996      0.995      0.734\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      18/29     0.862G    0.02721    0.02126  0.0008888         68        416: 100% 45/45 [00:07<00:00,  6.35it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.72it/s]\n","                   all        174        487      0.998      0.997      0.995       0.71\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      19/29     0.862G    0.02767    0.02143  0.0008134         65        416: 100% 45/45 [00:07<00:00,  6.30it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  4.04it/s]\n","                   all        174        487      0.996      0.996      0.995      0.723\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      20/29     0.862G    0.02645    0.02116  0.0007776         61        416: 100% 45/45 [00:07<00:00,  6.27it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.69it/s]\n","                   all        174        487      0.992      0.991      0.994      0.755\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      21/29     0.862G    0.02652    0.02053  0.0007445         60        416: 100% 45/45 [00:06<00:00,  6.55it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.36it/s]\n","                   all        174        487      0.997      0.997      0.995      0.776\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      22/29     0.862G    0.02525     0.0203   0.000626         60        416: 100% 45/45 [00:06<00:00,  6.54it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.50it/s]\n","                   all        174        487      0.997      0.999      0.995      0.772\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      23/29     0.862G    0.02475     0.0208  0.0005956         53        416: 100% 45/45 [00:07<00:00,  5.76it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.73it/s]\n","                   all        174        487      0.997          1      0.995      0.767\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      24/29     0.862G    0.02361     0.0201  0.0005766         63        416: 100% 45/45 [00:06<00:00,  6.43it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.55it/s]\n","                   all        174        487      0.994      0.996      0.995      0.754\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      25/29     0.862G    0.02334    0.01969  0.0005711         59        416: 100% 45/45 [00:07<00:00,  6.30it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.28it/s]\n","                   all        174        487      0.994      0.996      0.995      0.808\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      26/29     0.862G    0.02284    0.01989  0.0005188         88        416: 100% 45/45 [00:08<00:00,  5.36it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.42it/s]\n","                   all        174        487      0.995      0.996      0.995      0.818\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      27/29     0.862G    0.02195    0.01943  0.0004611         65        416: 100% 45/45 [00:06<00:00,  6.57it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.27it/s]\n","                   all        174        487      0.995      0.995      0.995      0.806\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      28/29     0.862G    0.02184    0.01899  0.0004487         64        416: 100% 45/45 [00:06<00:00,  6.54it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.58it/s]\n","                   all        174        487      0.995      0.996      0.994      0.825\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      29/29     0.862G    0.02132    0.01953  0.0004231         61        416: 100% 45/45 [00:06<00:00,  6.48it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:01<00:00,  5.56it/s]\n","                   all        174        487      0.995      0.996      0.994      0.832\n","\n","30 epochs completed in 0.073 hours.\n","Optimizer stripped from runs/train/exp/weights/last.pt, 3.8MB\n","Optimizer stripped from runs/train/exp/weights/best.pt, 3.8MB\n","\n","Validating runs/train/exp/weights/best.pt...\n","Fusing layers... \n","Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:02<00:00,  2.23it/s]\n","                   all        174        487      0.995      0.996      0.994      0.833\n","                laptop        174        143      0.996          1      0.995      0.927\n","                person        174        344      0.994      0.992      0.994      0.738\n","Results saved to \u001b[1mruns/train/exp\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"g8dHcni6CJYt"},"source":["# Download weights and export\n","\n","We can now download the .pt file and convert it to a .tflite file for CPU deployment"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"7iiObB2WCMh6","outputId":"2808ae03-2c08-4301-e939-9c826c914002","executionInfo":{"status":"ok","timestamp":1670432499428,"user_tz":300,"elapsed":6,"user":{"displayName":"Sean Thammakhoune","userId":"11730667877753326319"}}},"source":["#export your model's weights for future use\n","from google.colab import files\n","PATH_TO_WEIGHTS = './runs/train/exp/weights/best.pt'\n","!python export.py --w PATH_TO_WEIGHTS --img 416 --batch 1 --include tflite\n","files.download('./runs/train/exp/weights/best.pt')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_6a20b80d-aa57-4610-b853-c122b8d957cc\", \"best.pt\", 3774773)"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"rNn-obvOGITm"},"source":[],"execution_count":null,"outputs":[]}]}